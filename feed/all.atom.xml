<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Perfinion's Blog</title><link href="https://blog.perfinion.com/" rel="alternate"></link><link href="https://blog.perfinion.com/feed/all.atom.xml" rel="self"></link><id>https://blog.perfinion.com/</id><updated>2018-07-20T12:00:00+08:00</updated><entry><title>Tensorflow - Your CPU supports instructions that this binary was not compiled to use</title><link href="https://blog.perfinion.com/2018/07/tensorflow-cpu-supports-instructions/" rel="alternate"></link><published>2018-07-20T12:00:00+08:00</published><updated>2018-07-20T12:00:00+08:00</updated><author><name>Jason Zaman</name></author><id>tag:blog.perfinion.com,2018-07-20:/2018/07/tensorflow-cpu-supports-instructions/</id><summary type="html">&lt;p&gt;If you've installed TensorFlow from pip, you've probably come across this message:&lt;/p&gt;
tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports
instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
&lt;/pre&gt;


&lt;p&gt;Well, I did too and it got me wondering how much of a difference those
instructions end up making. People often say GPUs are required for any
non-trivial ML work so I wanted to see if that was really true. I decided to
delve in and optimize TensorFlow and make it faster on my machine. I gave a
talk about this yesterday, the slides will be attached at the end as well.&lt;/p&gt;
</summary><content type="html">&lt;p&gt;If you've installed TensorFlow from pip, you've probably come across this message:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports
instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Well, I did too and it got me wondering how much of a difference those
instructions end up making. People often say GPUs are required for any
non-trivial ML work so I wanted to see if that was really true. I decided to
delve in and optimize TensorFlow and make it faster on my machine. I gave a
talk about this yesterday, the slides will be attached at the end as well.&lt;/p&gt;


&lt;p&gt;I recently packaged TensorFlow on Gentoo (you can install it with &lt;code&gt;# emerge
tensorflow&lt;/code&gt;) and decided to compare it to the pip package to see how much of a
difference there would be. For the tests I didn't just want MNIST, I wanted
something a bit larger. I found the &lt;a href="https://github.com/tensorflow/models/tree/master/official/resnet"&gt;TensorFlow official models
repo&lt;/a&gt; and
thought ResNet would be big enough for some tests. ImageNet was a huge download
so I used CIFAR-10 instead. I also did a second smaller benchmark of a simple
&lt;code&gt;tf.matmul()&lt;/code&gt; for a few different sized matrices. Matrix multiplication is
one of the most key parts of ML so I thought that would be interesting to see.&lt;/p&gt;
&lt;h1&gt;Benchmarks&lt;/h1&gt;
&lt;p&gt;I tested this on both my powerful workstation and my old laptop to get the
spectrum of high-end and low-end. My workstation has an AMD Threadripper 1950x:
16 core / 32 thread, 3.4GHz base, 40MB cache total, and 32GB RAM. I also
recently got an Nvidia 1080Ti from the guys at &lt;a href="https://lambdal.com/"&gt;Lambda Labs&lt;/a&gt;
to get TF properly working on Gentoo with CUDA so I'll also be comparing that.
My laptop is a Haswell Core i7-4600U: 2.1GHz, 2 core / 4 thread, 4MB cache
total, and 12GB RAM and no GPU. All the tests were with TensorFlow v1.9.0: from
pip, built with portage, and built myself for GPU. The prebuilt pip packages
for tensorflow-gpu required an older version of CUDA than the one I had so I
didn't test that.&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="right"&gt;Steps&lt;/th&gt;
&lt;th&gt;100&lt;/th&gt;
&lt;th&gt;200&lt;/th&gt;
&lt;th&gt;300&lt;/th&gt;
&lt;th&gt;400&lt;/th&gt;
&lt;th&gt;500&lt;/th&gt;
&lt;th&gt;600&lt;/th&gt;
&lt;th&gt;700&lt;/th&gt;
&lt;th&gt;800&lt;/th&gt;
&lt;th&gt;900&lt;/th&gt;
&lt;th&gt;AVG&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="right"&gt;&lt;strong&gt;PIP&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;816.75&lt;/td&gt;
&lt;td&gt;811.48&lt;/td&gt;
&lt;td&gt;808.75&lt;/td&gt;
&lt;td&gt;817.62&lt;/td&gt;
&lt;td&gt;817.94&lt;/td&gt;
&lt;td&gt;812.81&lt;/td&gt;
&lt;td&gt;810.61&lt;/td&gt;
&lt;td&gt;812.37&lt;/td&gt;
&lt;td&gt;811.00&lt;/td&gt;
&lt;td&gt;813.26&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;&lt;strong&gt;SRC&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;632.77&lt;/td&gt;
&lt;td&gt;630.48&lt;/td&gt;
&lt;td&gt;625.17&lt;/td&gt;
&lt;td&gt;625.16&lt;/td&gt;
&lt;td&gt;617.06&lt;/td&gt;
&lt;td&gt;611.70&lt;/td&gt;
&lt;td&gt;616.83&lt;/td&gt;
&lt;td&gt;614.71&lt;/td&gt;
&lt;td&gt;618.39&lt;/td&gt;
&lt;td&gt;621.36&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="right"&gt;&lt;strong&gt;GPU&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;8.789&lt;/td&gt;
&lt;td&gt;8.681&lt;/td&gt;
&lt;td&gt;8.471&lt;/td&gt;
&lt;td&gt;9.173&lt;/td&gt;
&lt;td&gt;8.114&lt;/td&gt;
&lt;td&gt;8.148&lt;/td&gt;
&lt;td&gt;8.387&lt;/td&gt;
&lt;td&gt;8.194&lt;/td&gt;
&lt;td&gt;8.607&lt;/td&gt;
&lt;td&gt;8.507&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Times are in seconds per 100 steps on the cifar10 benchmark.&lt;/p&gt;
&lt;p&gt;PIP / SRC = &lt;strong&gt;1.31x speedup!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Thats pretty good. Obviously the GPU is way faster but just building TensorFlow
yourself already gives huge gains. This is a significant enough speedup that if
you want to train a big model, you could start from scratch and compile TF then
start training and still be done before just using the pip package. Sort of the
modern version of Abraham Lincoln's quote: "Give me six hours to chop down a
tree and I will spend the first four sharpening the axe."&lt;/p&gt;
&lt;p&gt;The matrix multiplication benchmark was a tf.matmul() with sizes from 256x256
up to 16384x16384.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Threadripper workstation:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="Matrix Multiplication on Threadripper" src="https://blog.perfinion.com/2018/07/tensorflow-cpu-supports-instructions/files/2018/tensorflow-matmul-threadripper.png"&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Haswell Laptop:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="Matrix Multiplication on Haswell" src="https://blog.perfinion.com/2018/07/tensorflow-cpu-supports-instructions/files/2018/tensorflow-matmul-haswell.png"&gt;&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Threadripper&lt;/th&gt;
&lt;th&gt;Haswell&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;PIP&lt;/td&gt;
&lt;td&gt;519.9 GFLOPs&lt;/td&gt;
&lt;td&gt;86.2 GFLOPs&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;SRC&lt;/td&gt;
&lt;td&gt;631.2 GFLOPs&lt;/td&gt;
&lt;td&gt;140.6 GFLOPs&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;GPU&lt;/td&gt;
&lt;td&gt;11657 GFLOPs&lt;/td&gt;
&lt;td&gt;N/A&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Threadripper workstation optimized speedup = &lt;strong&gt;1.22x!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Haswell laptop optimized speedup = &lt;strong&gt;1.63x!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The workstation had a decent speed jump but the laptop's jump was HUGE. The
Threadripper seemed fastest at 4k matrix sizes and laptop was fastest at 2k so
those are what I used. For 4k sizes on the laptop, optimizing was even better
at around 2x.&lt;/p&gt;
&lt;h1&gt;CPU Extensions&lt;/h1&gt;
&lt;p&gt;So clearly this makes a huge difference, but why? To answer that we need to go
back through computer history a little. Originally CPUs processed things one at
a time. If you need to multiply many numbers you load the first two, multiply,
save them. Load the next two, multiply, save. repeat over. and over. This is
called SISD: Single Instruction, Single Data. This was fine decades ago when
Moore's Law and Dennard Scaling worked. In the good old days, computers would
double in power every year. Then Moore's Law and Dennard Scaling started to
stop working and we moved to the multicore era. Things were still mostly okay,
a doubling in compute power would only take 3.5 years. Now all of that is
mostly over so we get closer to 3% increase per year.&lt;/p&gt;
&lt;p&gt;To get around these limitations, the hardware manufacturers started making
specialized extensions to the processors that could process many things at one.
This was called Single Instruction, Multiple Data. Originally they were used
for multimedia because video needs to play at 24 fps and computers were slow
originally. Over time these extensions could do more so now with AVX2 and FMA a
processor can do 256-bits worth of calculations at once.&lt;/p&gt;
&lt;p&gt;With &lt;a href="https://en.wikipedia.org/wiki/Advanced_Vector_Extensions"&gt;AVX2 (Advanced Vector
Extensions)&lt;/a&gt; a CPU
can multiply two sets of 8 numbers all at once. &lt;a href="https://en.wikipedia.org/wiki/Multiply%E2%80%93accumulate_operation#Fused_multiply%E2%80%93add"&gt;FMA (Fused
Multiply-Add)&lt;/a&gt;
is even better, it can do &lt;code&gt;a = a * b + c&lt;/code&gt; all at once where each of a, b, c are
8 32-bit floats. With FMA, AMD processors can theoretically do 16 FLOPs/cycle
and Intel processors can do double that. For my workstation CPU this works out
to be theoretically &lt;code&gt;16 FLOPs/cycle * 3.4 GHz * 16 cores = 870 GFLOPs&lt;/code&gt;, so
the benchmark is pretty good considering thats the absolute maximum theoretical
limit.&lt;/p&gt;
&lt;p&gt;AVX has been in processors since ~2011 while AVX2 and FMA have been in
processors since Intel Haswell and AMD Piledriver released in ~2012/2013. That
means if your computer is less than 5 years old you almost definitely have
support for these extensions already. Since TensorFlow 1.6, the pre-built pip
packages use AVX but not AVX2 or FMA yet. The point of the pip packages is to
work easily, not to give the absolute best performance so not including support
for AVX2 and FMA makes sense, it just means for best performance you should
build it yourself.&lt;/p&gt;
&lt;p&gt;These extensions can be enabled with GCC using the &lt;code&gt;-mavx2&lt;/code&gt; and &lt;code&gt;-mfma&lt;/code&gt;
flags. There are other GCC optimization flags that are helpful too: &lt;code&gt;gcc
-O&amp;lt;number&amp;gt;&lt;/code&gt; (O the letter, not the number).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;-O0: Turns off optimization entirely. Fast compile times, good for debugging.
  This is the default if you don't specify any which you probably don't want.&lt;/li&gt;
&lt;li&gt;-O1: Basic optimization level.&lt;/li&gt;
&lt;li&gt;-O2: Recommended for most things. SSE / AVX may be used, but not fully.&lt;/li&gt;
&lt;li&gt;-O3: Highest optimization possible. Also vectorizes loops, can use all AVX
  registers.&lt;/li&gt;
&lt;li&gt;-Os: Small size. Basically enables -O2 options which do not increase size.
  Can be useful for machines that have limited storage and/or CPUs with small
  cache sizes.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There are a lot of these extensions and knowing exactly which to use is
complicated so luckily GCC can figure it out on its own. If you are building
TensorFlow on the same machine that will be running it you can just use &lt;code&gt;-O3
-march=native&lt;/code&gt;. If you are building on a different machine, you can use the
command below to see which flags GCC would set and then pass them when
configuring TF. The Gentoo wiki also has some &lt;a href="https://wiki.gentoo.org/wiki/Safe_CFLAGS"&gt;safe
CFLAGS&lt;/a&gt; for common CPU types.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c c-Singleline"&gt;# This is the output on my machine:&lt;/span&gt;
$ &lt;span class="n"&gt;gcc&lt;/span&gt; -&lt;span class="n"&gt;march&lt;/span&gt;=&lt;span class="n"&gt;native&lt;/span&gt; -&lt;span class="n"&gt;E&lt;/span&gt; -&lt;span class="n"&gt;v&lt;/span&gt; - &lt;span class="s"&gt;&amp;lt;/dev/null 2&amp;gt;&lt;/span&gt;&lt;span class="nv"&gt;&amp;amp;1&lt;/span&gt; | &lt;span class="nb"&gt;grep&lt;/span&gt; &lt;span class="n"&gt;cc1&lt;/span&gt;
/&lt;span class="n"&gt;usr&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;libexec&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;gcc&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;x86_64-pc-linux-gnu&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mf"&gt;7.3.0&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="n"&gt;cc1&lt;/span&gt; -&lt;span class="n"&gt;E&lt;/span&gt; -&lt;span class="n"&gt;quiet&lt;/span&gt; -&lt;span class="n"&gt;v&lt;/span&gt; - -&lt;span class="n"&gt;march&lt;/span&gt;=&lt;span class="n"&gt;znver1&lt;/span&gt;
-&lt;span class="n"&gt;mmmx&lt;/span&gt; -&lt;span class="n"&gt;mno-3dnow&lt;/span&gt; -&lt;span class="n"&gt;msse&lt;/span&gt; -&lt;span class="n"&gt;msse2&lt;/span&gt; -&lt;span class="n"&gt;msse3&lt;/span&gt; -&lt;span class="n"&gt;mssse3&lt;/span&gt; -&lt;span class="n"&gt;msse4a&lt;/span&gt; -&lt;span class="n"&gt;mcx16&lt;/span&gt; -&lt;span class="n"&gt;msahf&lt;/span&gt; -&lt;span class="n"&gt;mmovbe&lt;/span&gt;
-&lt;span class="n"&gt;maes&lt;/span&gt; -&lt;span class="n"&gt;msha&lt;/span&gt; -&lt;span class="n"&gt;mpclmul&lt;/span&gt; -&lt;span class="n"&gt;mpopcnt&lt;/span&gt; -&lt;span class="n"&gt;mabm&lt;/span&gt; -&lt;span class="n"&gt;mno-lwp&lt;/span&gt; -&lt;span class="n"&gt;mfma&lt;/span&gt; -&lt;span class="n"&gt;mno-fma4&lt;/span&gt; -&lt;span class="n"&gt;mno-xop&lt;/span&gt; -&lt;span class="n"&gt;mbmi&lt;/span&gt;
-&lt;span class="n"&gt;mno-sgx&lt;/span&gt; -&lt;span class="n"&gt;mbmi2&lt;/span&gt; -&lt;span class="n"&gt;mno-tbm&lt;/span&gt; -&lt;span class="n"&gt;mavx&lt;/span&gt; -&lt;span class="n"&gt;mavx2&lt;/span&gt; -&lt;span class="n"&gt;msse4&lt;/span&gt;&lt;span class="mf"&gt;.2&lt;/span&gt; -&lt;span class="n"&gt;msse4&lt;/span&gt;&lt;span class="mf"&gt;.1&lt;/span&gt; -&lt;span class="n"&gt;mlzcnt&lt;/span&gt; -&lt;span class="n"&gt;mno-rtm&lt;/span&gt;
-&lt;span class="n"&gt;mno-hle&lt;/span&gt; -&lt;span class="n"&gt;mrdrnd&lt;/span&gt; -&lt;span class="n"&gt;mf16c&lt;/span&gt; -&lt;span class="n"&gt;mfsgsbase&lt;/span&gt; -&lt;span class="n"&gt;mrdseed&lt;/span&gt; -&lt;span class="n"&gt;mprfchw&lt;/span&gt; -&lt;span class="n"&gt;madx&lt;/span&gt; -&lt;span class="n"&gt;mfxsr&lt;/span&gt; -&lt;span class="n"&gt;mxsave&lt;/span&gt;
-&lt;span class="n"&gt;mxsaveopt&lt;/span&gt; -&lt;span class="n"&gt;mno-avx512f&lt;/span&gt; -&lt;span class="n"&gt;mno-avx512er&lt;/span&gt; -&lt;span class="n"&gt;mno-avx512cd&lt;/span&gt; -&lt;span class="n"&gt;mno-avx512pf&lt;/span&gt;
-&lt;span class="n"&gt;mno-prefetchwt1&lt;/span&gt; -&lt;span class="n"&gt;mclflushopt&lt;/span&gt; -&lt;span class="n"&gt;mxsavec&lt;/span&gt; -&lt;span class="n"&gt;mxsaves&lt;/span&gt; -&lt;span class="n"&gt;mno-avx512dq&lt;/span&gt; -&lt;span class="n"&gt;mno-avx512bw&lt;/span&gt;
-&lt;span class="n"&gt;mno-avx512vl&lt;/span&gt; -&lt;span class="n"&gt;mno-avx512ifma&lt;/span&gt; -&lt;span class="n"&gt;mno-avx512vbmi&lt;/span&gt; -&lt;span class="n"&gt;mno-avx5124fmaps&lt;/span&gt;
-&lt;span class="n"&gt;mno-avx5124vnniw&lt;/span&gt; -&lt;span class="n"&gt;mno-clwb&lt;/span&gt; -&lt;span class="n"&gt;mmwaitx&lt;/span&gt; -&lt;span class="n"&gt;mclzero&lt;/span&gt; -&lt;span class="n"&gt;mno-pku&lt;/span&gt; -&lt;span class="n"&gt;mno-rdpid&lt;/span&gt; --&lt;span class="n"&gt;param&lt;/span&gt;
&lt;span class="n"&gt;l1-cache-size&lt;/span&gt;=&lt;span class="mi"&gt;32&lt;/span&gt; --&lt;span class="n"&gt;param&lt;/span&gt; &lt;span class="n"&gt;l1-cache-line-size&lt;/span&gt;=&lt;span class="mi"&gt;64&lt;/span&gt; --&lt;span class="n"&gt;param&lt;/span&gt; &lt;span class="n"&gt;l2-cache-size&lt;/span&gt;=&lt;span class="mi"&gt;512&lt;/span&gt;
-&lt;span class="n"&gt;mtune&lt;/span&gt;=&lt;span class="n"&gt;znver1&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h1&gt;Bazel&lt;/h1&gt;
&lt;p&gt;TensorFlow is built using &lt;a href="https://bazel.build"&gt;Bazel&lt;/a&gt; a build system Open
Sourced by Google based on their internal one called Blaze. It is designed to
be fast, scalable, and correct. Fast and scalable I agree with. It is correct
for how Google uses it, which is not quite as friendly for how normal distros
build things, though features to make it easier to use for distros are on the
roadmap.&lt;/p&gt;
&lt;p&gt;Once you get used to it, its fairly simple and powerful. The root of the repo
contains a WORKSPACE file, and build targets are declared in BUILD files. There
are tons of docs on the site, but to just build TensorFlow you just need to
know commands look like: &lt;code&gt;$ bazel build //main:helloworld&lt;/code&gt;. No, that is not a
typo. Yes, there really are two slashes at the front.&lt;/p&gt;
&lt;p&gt;Building TensorFlow is fairly simple, full docs are
&lt;a href="https://www.tensorflow.org/install/install_sources"&gt;here&lt;/a&gt; but here's a
summary.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ git clone https://github.com/tensorflow/tensorflow.git
$ &lt;span class="nb"&gt;cd&lt;/span&gt; tensorflow
$ git checkout v1.9.0
$ ./configure
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Configure will ask many questions, it will build faster if you turn off the
ones you don't need. &lt;code&gt;./configure&lt;/code&gt; is a python script, it has nothing to do
with autoconf. The more important ones to look for are:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;Do you wish to build TensorFlow with CUDA support? [y/N]: n
No CUDA support will be enabled for TensorFlow.

Please specify optimization flags to use during compilation when bazel option &amp;quot;--config=opt&amp;quot; is specified [Default is -march=native]: -O3 -march=native
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Turn CUDA off if you don't have a GPU, it takes ages to build. The optimization
one is where you give it the flags we discussed above. Once its all ready, just
run:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ bazel build --config&lt;span class="o"&gt;=&lt;/span&gt;opt &lt;span class="se"&gt;\&lt;/span&gt;
//tensorflow/tools/pip_package:build_pip_package &lt;span class="se"&gt;\&lt;/span&gt;
//tensorflow:libtensorflow_framework.so &lt;span class="se"&gt;\&lt;/span&gt;
//tensorflow:libtensorflow.so

$ bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tf/
$ pip install /tmp/tf/tensorflow-*.whl
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The &lt;code&gt;--config=opt&lt;/code&gt; flag is important otherwise it won't use the optimization
flags you specified. Alternatively, I've done all the work already on Gentoo so
just use: &lt;code&gt;# emerge tensorflow&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;If you're using GPUs for TensorFlow you may be wondering why bother with all
this? TensorFlow's gpu packages currently are built for CUDA 9.0, the latest is
9.2. Nvidia GPUs have "Compute Capabilities" which should ideally match your
card. Anything lower will work but you may be missing out features. The
pre-built ones are for "3.5,5.2", you can see what level your card is
&lt;a href="https://developer.nvidia.com/cuda-gpus"&gt;here&lt;/a&gt;. Also, not everything can run on
a GPU, the input pipeline is all on the CPU so especially if you're training
with lots of fast cards, you'll want the CPU portions to be as optimized as
possible to keep up. When using the Gentoo package, TF will try to autodetect
which capabilities your card has. You can set
&lt;code&gt;TF_CUDA_COMPUTE_CAPABILITIES="6.1"&lt;/code&gt; in your make.conf to force a specific
version.&lt;/p&gt;
&lt;p&gt;The slides from my talk are
&lt;a href="https://blog.perfinion.com/2018/07/tensorflow-cpu-supports-instructions/files/2018/Tensorflow_2018_Optimizing_Your_Tensorflow.pdf"&gt;here&lt;/a&gt; and
unfortunately, it was not recorded. The matmul benchmark is on
&lt;a href="https://github.com/perfinion/tfbench"&gt;Github&lt;/a&gt;. I'd be interested to see
results from running it on other systems too.&lt;/p&gt;</content><category term="talks"></category><category term="tensorflow"></category></entry><entry><title>FOSSASIA 2018 - SELinux Policy Development</title><link href="https://blog.perfinion.com/2018/05/fossasia-2018-selinux-policy-dev/" rel="alternate"></link><published>2018-05-04T00:00:00+08:00</published><updated>2018-05-04T00:00:00+08:00</updated><author><name>Jason Zaman</name></author><id>tag:blog.perfinion.com,2018-05-04:/2018/05/fossasia-2018-selinux-policy-dev/</id><summary type="html">A month ago was FOSSASIA 2018 and I got to give another talk about SELinux.
Last years talk was only about the basics of how things SELinux works and
labels and allow rules. This year covered more of the policy side of things. I
went over now to write a Reference Policy module and did a quick demo.</summary><content type="html">&lt;p&gt;A month ago was FOSSASIA 2018 and I got to give another talk about SELinux.
Last years talk was only about the basics of how things SELinux works and
labels and allow rules. This year covered more of the policy side of things. I
went over now to write a Reference Policy module and did a quick demo.&lt;/p&gt;
&lt;p&gt;I started off showing the different parts of a policy as far as the kernel and
other tools are concerned, &lt;code&gt;/etc/selinux/strict/policy/policy.31&lt;/code&gt; is the big
blob that gets loaded into the kernel when you boot. Then there are the file
contexts which live in &lt;code&gt;/etc/selinux/strict/contexts/files/&lt;/code&gt;. These don't get
loaded in the kernel but are used by various userspace tools to lookup labels.
For example when you restorecon something it will look there, or maybe a daemon
like udev needs to know what fcontext should be applied to a device node when
you plug something in. There are three main files with the fcontexts:
&lt;code&gt;file_contexts&lt;/code&gt;, &lt;code&gt;file_contexts.home_dirs&lt;/code&gt;, &lt;code&gt;file_contexts.local&lt;/code&gt; The
base one has all the main labels for your entire system as defined by the
distros policy.  home_dirs is generated whenever the policy is loaded and
contains the contexts customized for each user on the system. Any fcontexts
that start with &lt;code&gt;HOME_DIR&lt;/code&gt; are automatically re-written for each user based
on their selinux user and role.  It also supports rewriting based on &lt;code&gt;USERID&lt;/code&gt;
or &lt;code&gt;USERNAME&lt;/code&gt; which is usually needed for things in /run/user/.  Finally, the
.local file is where any fcontexts that are added using semanage fcontext end
up.&lt;/p&gt;
&lt;p&gt;Then I showed how the entire policy above is compiled from separate modules.
Reference Policy (aka refpolicy) is how most selinux modules are written. It is
made up of a bunch of m4 macros to simplify things that happen together often.
For example reading a file requires maybe getattr'ing it then opening then
finally a read system call. We simplify this down this set to
&lt;code&gt;read_file_perms&lt;/code&gt;. They all follow a consisten naming scheme so you quickly
know what each does. They are &lt;code&gt;&amp;lt;perm&amp;gt;_&amp;lt;class&amp;gt;_perms&lt;/code&gt;, where perm is something
like setattr, read, write, manage, and class is something like file, dir,
lnk_file.&lt;/p&gt;
&lt;p&gt;Patterns are the next building block. Lots of things require many other
operations to actually work, for example creating a file requires being able to
access the directory that it's in.  There are patterns like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;define(`write_files_pattern&amp;#39;,`
    allow $1 $2:dir search_dir_perms;
    allow $1 $3:file write_file_perms;
&amp;#39;)
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You call it like &lt;code&gt;write_files_pattern(app_t, var_log_t, app_log_t)&lt;/code&gt; and it will
grant you the minimum accesses you need to var_log_t dirs and then give you
write access to app_log_t.&lt;/p&gt;
&lt;p&gt;Each module that makes up an SELinux policy is supposed to be completely
self-contained and can only refer to things it itself defines. In order to make
rules relating to other modules, each refpolicy module has a ton of interfaces.
These look like: &lt;code&gt;modulename[_modifier]_verb_predicate()&lt;/code&gt;, for example:
&lt;code&gt;apache_append_log(app_t)&lt;/code&gt; or &lt;code&gt;logging_log_filetrans(app_t, app_log_t, file)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;The last part i covered in the slides was a small tool written by Sven
Vermeulen to find and show interfaces and defines.  They are defined
&lt;a href="https://github.com/sjvermeu/small.coding/blob/master/selinux-local/localfuncs"&gt;here.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I did pass around a VM image so people could follow along and play with the
small demo policy I made. I won't be uploading the image here since it was
purposefully made to be insecure and that seems like a bad idea. You can use
any Gentoo or redhat VM with SELinux enabled and just use the policy below.:&lt;/p&gt;
&lt;p&gt;The slides from the presentation are &lt;a href="https://blog.perfinion.com/2018/05/fossasia-2018-selinux-policy-dev/files/2018/FOSSASIA_2018_SELinux_Policy_Development.pdf"&gt;here.&lt;/a&gt;
The recording is &lt;a href="https://www.youtube.com/watch?v=GWy6vXIQxkc"&gt;here.&lt;/a&gt;&lt;/p&gt;
&lt;h2&gt;myapp.te&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;policy_module(myapp, 0.1)

###########################
#
# declarations
#

type myapp_t;
type myapp_exec_t;
userdom_user_application_domain(myapp_t, myapp_exec_t)

type myapp_log_t;
logging_log_file(myapp_log_t)


###########################
#
# myapp_t local policy
#

allow myapp_t self:tcp_socket create_stream_socket_perms;

allow myapp_t myapp_log_t:file manage_file_perms;
logging_log_filetrans(myapp_t, myapp_log_t, file)

corecmd_exec_bin(myapp_t)
corenet_tcp_bind_generic_node(myapp_t)
corenet_tcp_bind_http_cache_port(myapp_t)

files_read_etc_files(myapp_t)
files_read_etc_runtime(myapp_t)

sysnet_read_config(myapp_t)

domain_use_interactive_fds(myapp_t)
miscfiles_read_localization(myapp_t)

userdom_use_inherited_user_terminals(myapp_t)
userdom_read_user_home_content_files(myapp_t)

# this should properly be in staff.te

gen_require(`
        type staff_t, sysadm_t;
        role staff_r, sysadm_r;
&amp;#39;)
myapp_role(staff_r, staff_t)
myapp_role(sysadm_r, sysadm_t)
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;myapp.if&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;## &amp;lt;summary&amp;gt;Myapp client&amp;lt;/summary&amp;gt;

#######################################
## &amp;lt;summary&amp;gt;
##      The role for using the myapp client.
## &amp;lt;/summary&amp;gt;
## &amp;lt;param name=&amp;quot;role&amp;quot;&amp;gt;
##      &amp;lt;summary&amp;gt;
##      The role associated with the user domain.
##      &amp;lt;/summary&amp;gt;
## &amp;lt;/param&amp;gt;
## &amp;lt;param name=&amp;quot;domain&amp;quot;&amp;gt;
##      &amp;lt;summary&amp;gt;
##      The user domain.
##      &amp;lt;/summary&amp;gt;
## &amp;lt;/param&amp;gt;
#
interface(`myapp_role&amp;#39;,`
        gen_require(`
                type myapp_t;
                type myapp_exec_t;
        &amp;#39;)

        role $1 types myapp_t;

        domtrans_pattern($2, myapp_exec_t, myapp_t)

        allow $2 myapp_t:process { ptrace signal_perms };

        ps_process_pattern($2, myapp_t)
&amp;#39;)
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;myapp.fc&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;/usr/local/bin/server.py    --    gen_context(system_u:object_r:myapp_exec_t,s0)
&lt;/pre&gt;&lt;/div&gt;</content><category term="selinux"></category><category term="talks"></category><category term="fossasia"></category></entry><entry><title>FOSSASIA 2017 - SELinux Introduction talk</title><link href="https://blog.perfinion.com/2017/03/fossasia-2017-selinux-introduction/" rel="alternate"></link><published>2017-03-19T17:00:00+08:00</published><updated>2017-03-19T17:00:00+08:00</updated><author><name>Jason Zaman</name></author><id>tag:blog.perfinion.com,2017-03-19:/2017/03/fossasia-2017-selinux-introduction/</id><summary type="html">FOSSASIA 2017 was this weekend and I gave an introductory talk on SELinux.
&lt;a href="http://2017.fossasia.org/"&gt;The event details are here.&lt;/a&gt; There were a lot of
great talks over the three days. Engineers.sg filmed all the talks too so you
can see them all on the &lt;a href="https://www.youtube.com/channel/UCQprMsG-raCIMlBudm20iLQ"&gt;FOSSASIA youtube
channel.&lt;/a&gt;</summary><content type="html">&lt;p&gt;FOSSASIA 2017 was this weekend and I gave an introductory talk on SELinux.
&lt;a href="http://2017.fossasia.org/"&gt;The event details are here.&lt;/a&gt; There were a lot of
great talks over the three days. Engineers.sg filmed all the talks too so you
can see them all on the &lt;a href="https://www.youtube.com/channel/UCQprMsG-raCIMlBudm20iLQ"&gt;FOSSASIA youtube
channel.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;In my talk I tried to give a quick overview of SELinux so that people would be
more familiar with the basic concepts behind SELinux. I covered DAC vs MAC,
SELinux labels and basics of how the rules are layed out. There were lots of
great questions too and we had some fun playing around with a little backdoor
shell in the webserver and the protections that SELinux had.&lt;/p&gt;
&lt;p&gt;The slides from the presentation are &lt;a href="https://blog.perfinion.com/2017/03/fossasia-2017-selinux-introduction/files/2017/FOSSASIA_2017_SELinux_Introduction.pdf"&gt;here.&lt;/a&gt;
The recording is &lt;a href="https://www.youtube.com/watch?v=FRdk9xA6lA0"&gt;here.&lt;/a&gt;&lt;/p&gt;</content><category term="selinux"></category><category term="talks"></category><category term="fossasia"></category></entry><entry><title>GDG-SG DevFest 2016 - Android: Under the Hood</title><link href="https://blog.perfinion.com/2016/11/gdg-sg-devfest-android-under-the-hood/" rel="alternate"></link><published>2016-11-07T12:00:00+08:00</published><updated>2016-11-07T12:00:00+08:00</updated><author><name>Jason Zaman</name></author><id>tag:blog.perfinion.com,2016-11-07:/2016/11/gdg-sg-devfest-android-under-the-hood/</id><summary type="html">GDG-SG had its annual DevFest on Saturday. I gave a talk on a quick overview
of the internals of Android.</summary><content type="html">&lt;p&gt;GDG-SG had its annual DevFest on Saturday. I gave a talk on a quick overview
of the internals of Android.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.gdg-sg.org/2016/09/gdg-devfest-2016-coming-soon.html"&gt;The event details are here.&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Android is such a huge topic and I barely managed to skim the surface. I tried
to cover some of the key points in Android and compare them to a regular Linux
distro. There are a lot of things that are different but also a lot that is the
same. Hopefully the talk helped give some insight to how and why things are
designed as they are.&lt;/p&gt;
&lt;p&gt;The slides from the presentation are &lt;a href="https://blog.perfinion.com/2016/11/gdg-sg-devfest-android-under-the-hood/files/2016/GDG_DevFest_2016_Android_Under_the_Hood.pdf"&gt;here.&lt;/a&gt;&lt;/p&gt;</content><category term="android"></category><category term="talks"></category></entry><entry><title>SELinux userspace 2.6 released</title><link href="https://blog.perfinion.com/2016/10/selinux-userspace-26-released/" rel="alternate"></link><published>2016-10-30T12:00:00+08:00</published><updated>2016-10-30T12:00:00+08:00</updated><author><name>Jason Zaman</name></author><id>tag:blog.perfinion.com,2016-10-30:/2016/10/selinux-userspace-26-released/</id><summary type="html">The SELinux userspace libraries and programs recently released version 2.6. I
bumped them in Gentoo a couple days ago. They add a ton of new features, here
are a few of the main points:</summary><content type="html">&lt;p&gt;The SELinux userspace libraries and programs recently released version 2.6. I
bumped them in Gentoo a couple days ago. They add a ton of new features, here
are a few of the main points:&lt;/p&gt;
&lt;p&gt;I finally got semanage and sepolicy updated to use setools4. Setools4 replaces
setools3 which has been unmaintained for quite a long time and had issues with
the new policy versions. If you previously had &lt;code&gt;policy-version = 29&lt;/code&gt; in your
&lt;code&gt;/etc/selinux/semanage.conf&lt;/code&gt;, you can comment it out after updating to
app-admin/setools-4.0.&lt;/p&gt;
&lt;p&gt;genhomedircon has a ton of updates. I added new templating patterns that are
expanded for usernames and ids. I added support for &lt;code&gt;%{USERNAME}&lt;/code&gt; and &lt;code&gt;%{USERID}&lt;/code&gt;
to expand in fcontexts. This was primarily for &lt;code&gt;$XDG_RUNTIME_DIR&lt;/code&gt; adding
&lt;code&gt;/run/user/%{USERID}&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;genhomedircon finally has support for %group syntax in the list of users. You
can now do:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;semanage login --add -s staff_u -r &lt;span class="s1"&gt;&amp;#39;s0-s0:c0.c1023&amp;#39;&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;%wheel&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Instead of having to hardcode all the admins usernames. This is something I'd
wanted for ages but didn't get around to, so thanks a ton to Gary for this.
Once this has all gone stable I'll look into adding this automatically to
seusers.&lt;/p&gt;
&lt;p&gt;genhomedircon now replaces the whole context instead of only the user part.
This means genhomedircon can support RBACSEP now. This is role-based separation
instead of UBAC like we currently have in gentoo. UBAC has some limitations
about switching users that RBACSEP can would be able to fix. Because of this,
entries mapped to the default user and system_u are no longer special-cased.
This fixes an issue if a user had a homedir that was not in /home the fcontexts
would be missing. There is another side effect of this fix, there is now a
warning printed:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;libsemanage.add_user: user system_u not in password file
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This is caused by:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# semanage login -l&lt;/span&gt;
system_u    system_u    s0-s0:c0.c1023    *
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The warning is non-fatal and doesn't actually cause any problems. It is because
system_u is not a valid Linux user so the line is nonsense. I will remove this
line from seusers in the policy when I add %wheel. If you want to make the warning go away now, you can run:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;semanage login --delete system_u
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;There is also a pcre2 USE-flag for using libpcre2 instead of libcpre. The
default is still pcre1 because pcre2 takes up more disk space in the
file_contexts.bin files.&lt;/p&gt;
&lt;p&gt;The full announcement email is &lt;a href="https://marc.info/?l=selinux&amp;amp;m=147646050027049&amp;amp;w=2"&gt;here&lt;/a&gt;&lt;/p&gt;</content><category term="security"></category><category term="gentoo"></category></entry><entry><title>SELinux desktop profile in Gentoo</title><link href="https://blog.perfinion.com/2016/09/selinux-desktop-profile/" rel="alternate"></link><published>2016-09-21T12:00:00+08:00</published><updated>2016-10-05T22:00:00+08:00</updated><author><name>Jason Zaman</name></author><id>tag:blog.perfinion.com,2016-09-21:/2016/09/selinux-desktop-profile/</id><summary type="html">SELinux desktop profiles came up on IRC earlier and I thought it might be a good idea to make a post about.
Currently in gentoo there are only two selinux profiles:</summary><content type="html">&lt;p&gt;SELinux desktop profiles came up on IRC earlier and I thought it might be a good idea to make a post about.
Currently in gentoo there are only two selinux profiles:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;meriadoc ~ # eselect profile list
Available profile symlink targets:
  [1]   default/linux/amd64/13.0
  [2]   default/linux/amd64/13.0/selinux
  [3]   default/linux/amd64/13.0/desktop
  [4]   default/linux/amd64/13.0/desktop/gnome
  [5]   default/linux/amd64/13.0/desktop/gnome/systemd
  [6]   default/linux/amd64/13.0/desktop/kde
  [7]   default/linux/amd64/13.0/desktop/kde/systemd
  [8]   default/linux/amd64/13.0/desktop/plasma
  [9]   default/linux/amd64/13.0/desktop/plasma/systemd
  [10]  default/linux/amd64/13.0/developer
  [11]  default/linux/amd64/13.0/no-multilib
  [12]  default/linux/amd64/13.0/systemd
  [13]  default/linux/amd64/13.0/x32
  [14]  hardened/linux/amd64
  [15]  hardened/linux/amd64/selinux *
  [16]  hardened/linux/amd64/no-multilib
  [17]  hardened/linux/amd64/no-multilib/selinux
  [18]  hardened/linux/amd64/x32
  [19]  hardened/linux/musl/amd64
  [20]  hardened/linux/musl/amd64/x32
  [21]  default/linux/uclibc/amd64
  [22]  hardened/linux/uclibc/amd64
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;How would one go about having both default/linux/amd64/13.0/desktop and
selinux? We &lt;em&gt;could&lt;/em&gt; add selinux versions of every single other profile but that
would very quickly get unmanageable. Turns out making a custom one is pretty
simple:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;unlink /etc/portage/make.profile
mkdir /etc/portage/make.profile

&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="m"&gt;6&lt;/span&gt; &amp;gt; /etc/portage/make.profile/eapi
&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;gentoo:default/linux/amd64/13.0/desktop&amp;quot;&lt;/span&gt; &amp;gt; /etc/portage/make.profile/parent
&lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;gentoo:features/selinux&amp;quot;&lt;/span&gt; &amp;gt;&amp;gt; /etc/portage/make.profile/parent
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The parent file will tell portage to first use the desktop profile and then use
the selinux feature on top. It is important that the selinux line comes last
since it needs to override several things that might be set earlier in the
desktop profile.&lt;/p&gt;</content><category term="security"></category></entry><entry><title>Trusted Boot Part 1</title><link href="https://blog.perfinion.com/2016/08/trusted-boot-part1/" rel="alternate"></link><published>2016-08-30T12:00:00+08:00</published><updated>2016-08-30T12:00:00+08:00</updated><author><name>Jason Zaman</name></author><id>tag:blog.perfinion.com,2016-08-30:/2016/08/trusted-boot-part1/</id><summary type="html">I finally managed to get tboot working in a way that makes sense to me. For
those unfamiliar, tboot uses Intel's Trusted eXecution Technology to invoke a
dynamic root of trust and then measure all the components you boot with (eg
kernel and initrd). What took me ages to figure out was how one can upgrade
kernels while keeping this chain working.</summary><content type="html">&lt;p&gt;I finally managed to get tboot working in a way that makes sense to me. For
those unfamiliar, tboot uses Intel's Trusted eXecution Technology to invoke a
dynamic root of trust and then measure all the components you boot with (eg
kernel and initrd). What took me ages to figure out was how one can upgrade
kernels while keeping this chain working.&lt;/p&gt;
&lt;p&gt;There are two policies in tboot: Launch Control Policy and Verified Launch
Policy. LCP is handled by TXT automagically and is used to make sure the
correct tboot and PCRs are set and either continues boot by executing tboot or
resets the machine. VLP is where the kernel, initrd and any other components
are measured and is handled by tboot after the SINIT has happened.&lt;/p&gt;
&lt;p&gt;The trick I finally figured out is that the policy list needs to be signed with
your own key.  If the policy unsigned (unfortunately what most documentation
shows :-() then tboot will verify the kernels and extend the sha1 hash of the
policy file into PCR 18. This obviously causes problems when upgrading kernels
because everything changes.&lt;/p&gt;
&lt;p&gt;The difference with a signed policy is that instead of using the sha1 of the
policy file itself, tboot will use the sha1 of the signed public key which is
easily kept the same! hurrah!  Now finally I can update kernels and PCR 18 is
unchanged so there is no mess with migrating sealed secrets to new, probably
unknown, PCRs.&lt;/p&gt;
&lt;p&gt;I have extended genkernel to include all the tools needed to start tcsd and
tpm_unsealdata and can successfully unseal a secret from the prompt within the
initrd. Next I need to add the parts to automatically unseal and unlock the
LUKS drive. There will be another post when that's all working.&lt;/p&gt;
&lt;p&gt;Here is the Makefile that I used to output and setup my policies:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="nv"&gt;KVERS&lt;/span&gt; &lt;span class="o"&gt;:=&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;shell readlink /usr/src/linux &lt;span class="p"&gt;|&lt;/span&gt; sed &lt;span class="s1"&gt;&amp;#39;s/^linux-//&amp;#39;&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;
&lt;span class="nv"&gt;CMDLINE_TBOOT&lt;/span&gt; &lt;span class="o"&gt;:=&lt;/span&gt; &lt;span class="k"&gt;$(&lt;/span&gt;shell &lt;span class="nb"&gt;source&lt;/span&gt; /etc/default/grub-tboot&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="nb"&gt;echo&lt;/span&gt; &lt;span class="nv"&gt;$$&lt;/span&gt;&lt;span class="o"&gt;{&lt;/span&gt;GRUB_CMDLINE_TBOOT&lt;span class="o"&gt;}&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;

&lt;span class="nf"&gt;all&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;list&lt;/span&gt;.&lt;span class="n"&gt;pol&lt;/span&gt; &lt;span class="n"&gt;list&lt;/span&gt;.&lt;span class="n"&gt;data&lt;/span&gt;

&lt;span class="nf"&gt;clean&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
    rm -f list* mle* *.elt vl.pol pcrs.txt

&lt;span class="c"&gt;# Launch Control Policy element for MLE&lt;/span&gt;
&lt;span class="nf"&gt;mle_hash&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; /&lt;span class="n"&gt;boot&lt;/span&gt;/&lt;span class="n"&gt;tboot&lt;/span&gt;.&lt;span class="n"&gt;gz&lt;/span&gt; /&lt;span class="n"&gt;etc&lt;/span&gt;/&lt;span class="n"&gt;default&lt;/span&gt;/&lt;span class="n"&gt;grub&lt;/span&gt;-&lt;span class="n"&gt;tboot&lt;/span&gt;
    lcp_mlehash -c &lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="k"&gt;$(&lt;/span&gt;CMDLINE_TBOOT&lt;span class="k"&gt;)&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt; /boot/tboot.gz &amp;gt; mle_hash

&lt;span class="nf"&gt;mle.elt&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;mle_hash&lt;/span&gt;
    lcp_crtpolelt --create --ctrl 0x01 --type mle --minver &lt;span class="m"&gt;17&lt;/span&gt; --out mle.elt mle_hash

&lt;span class="c"&gt;# LCP element for pcrs&lt;/span&gt;
&lt;span class="nf"&gt;pcrs.txt&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; /&lt;span class="n"&gt;sys&lt;/span&gt;/&lt;span class="n"&gt;class&lt;/span&gt;/&lt;span class="n"&gt;tpm&lt;/span&gt;/&lt;span class="n"&gt;tpm&lt;/span&gt;0/&lt;span class="n"&gt;device&lt;/span&gt;/&lt;span class="n"&gt;pcrs&lt;/span&gt;
    egrep &lt;span class="s2"&gt;&amp;quot;^PCR-00&amp;quot;&lt;/span&gt; /sys/class/tpm/tpm0/device/pcrs &amp;gt; pcrs.txt

&lt;span class="nf"&gt;pconf.elt&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;pcrs&lt;/span&gt;.&lt;span class="n"&gt;txt&lt;/span&gt;
    lcp_crtpolelt --create --ctrl 0x01 --type pconf --out pconf.elt pcrs.txt


&lt;span class="c"&gt;# Make list out of all the policy elements&lt;/span&gt;
&lt;span class="nf"&gt;list_unsig.lst&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;mle&lt;/span&gt;.&lt;span class="n"&gt;elt&lt;/span&gt; &lt;span class="n"&gt;pconf&lt;/span&gt;.&lt;span class="n"&gt;elt&lt;/span&gt; &lt;span class="n"&gt;vl&lt;/span&gt;.&lt;span class="n"&gt;elt&lt;/span&gt;
    lcp_crtpollist --create --out list_unsig.lst mle.elt pconf.elt vl.elt

&lt;span class="c"&gt;# Sign the LCP so the pubkey is extended and NVRam is invariant&lt;/span&gt;
&lt;span class="nf"&gt;list_sig.lst&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;list_unsig&lt;/span&gt;.&lt;span class="n"&gt;lst&lt;/span&gt;
    cp list_unsig.lst list_sig.lst
    lcp_crtpollist --sign --pub pubkey.pem --priv privkey.pem --out list_sig.lst

&lt;span class="c"&gt;# Policy type lists need to have both .pol (in NVRAM) and data separately (loaded by grub)&lt;/span&gt;
&lt;span class="nf"&gt;list.data&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;list_sig&lt;/span&gt;.&lt;span class="n"&gt;lst&lt;/span&gt;
    lcp_crtpol2 --create --ctrl 0x00 --type list --pol list.pol --data list.data list_sig.lst

&lt;span class="nf"&gt;list.pol&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;list&lt;/span&gt;.&lt;span class="n"&gt;data&lt;/span&gt;


&lt;span class="c"&gt;# Verified Launch Policy for tboot to verify kernel+initrd&lt;/span&gt;
&lt;span class="c"&gt;# ctrl 0x00 means it does not extend module 0 into pcr18&lt;/span&gt;
&lt;span class="nf"&gt;vl.pol&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; /&lt;span class="n"&gt;boot&lt;/span&gt;/&lt;span class="n"&gt;initramfs&lt;/span&gt;-&lt;span class="n"&gt;genkernel&lt;/span&gt;-&lt;span class="n"&gt;x&lt;/span&gt;86&lt;span class="n"&gt;_&lt;/span&gt;64-&lt;span class="k"&gt;$(&lt;/span&gt;&lt;span class="nv"&gt;KVERS&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;  /&lt;span class="n"&gt;boot&lt;/span&gt;/&lt;span class="n"&gt;vmlinuz&lt;/span&gt;-&lt;span class="k"&gt;$(&lt;/span&gt;&lt;span class="nv"&gt;KVERS&lt;/span&gt;&lt;span class="k"&gt;)&lt;/span&gt;
    tb_polgen --create --ctrl 0x00 --type &lt;span class="k"&gt;continue&lt;/span&gt; vl.pol
    tb_polgen --add --num &lt;span class="m"&gt;0&lt;/span&gt; --pcr &lt;span class="m"&gt;19&lt;/span&gt; --hash image --cmdline &lt;span class="s2"&gt;&amp;quot;root=/dev/mapper/root ro console=ttyS0,115200n8 console=tty0 intel_iommu=on noefi&amp;quot;&lt;/span&gt; --image /boot/vmlinuz-&lt;span class="k"&gt;$(&lt;/span&gt;KVERS&lt;span class="k"&gt;)&lt;/span&gt; vl.pol
    tb_polgen --add --num &lt;span class="m"&gt;1&lt;/span&gt; --pcr &lt;span class="m"&gt;20&lt;/span&gt; --hash image --cmdline &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt; --image /boot/initramfs-genkernel-x86_64-&lt;span class="k"&gt;$(&lt;/span&gt;KVERS&lt;span class="k"&gt;)&lt;/span&gt; vl.pol

&lt;span class="nf"&gt;vl.elt&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;vl&lt;/span&gt;.&lt;span class="n"&gt;pol&lt;/span&gt;
    lcp_crtpolelt --create --ctrl 0x01 --type custom --out vl.elt --uuid tboot vl.pol


&lt;span class="c"&gt;# define the indexes in the TPM&lt;/span&gt;
&lt;span class="nf"&gt;definenv&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;
&lt;span class="c"&gt;    # define the error locality&lt;/span&gt;
    tpmnv_defindex -i 0x20000002 -s &lt;span class="m"&gt;8&lt;/span&gt; -pv &lt;span class="m"&gt;0&lt;/span&gt; -rl 0x07 -wl 0x07 -p &lt;span class="k"&gt;$(&lt;/span&gt;PASSWORD&lt;span class="k"&gt;)&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; &lt;span class="nb"&gt;true&lt;/span&gt;
&lt;span class="c"&gt;    # define the tboot verified launch policy locality&lt;/span&gt;
    tpmnv_defindex -i 0x20000001 -s &lt;span class="m"&gt;512&lt;/span&gt; -pv 0x02 -p &lt;span class="k"&gt;$(&lt;/span&gt;PASSWORD&lt;span class="k"&gt;)&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; &lt;span class="nb"&gt;true&lt;/span&gt;
&lt;span class="c"&gt;    # define the TXT launch control policy locality&lt;/span&gt;
    tpmnv_defindex -i owner -s 0x36 -p &lt;span class="k"&gt;$(&lt;/span&gt;PASSWORD&lt;span class="k"&gt;)&lt;/span&gt; &lt;span class="o"&gt;||&lt;/span&gt; &lt;span class="nb"&gt;true&lt;/span&gt;


&lt;span class="c"&gt;# write everything to tpm and /boot&lt;/span&gt;
&lt;span class="nf"&gt;writelcp&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;list&lt;/span&gt;.&lt;span class="n"&gt;pol&lt;/span&gt;
    lcp_writepol -i owner -f list.pol -p &lt;span class="k"&gt;$(&lt;/span&gt;PASSWORD&lt;span class="k"&gt;)&lt;/span&gt;

&lt;span class="nf"&gt;writevlp&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;vl&lt;/span&gt;.&lt;span class="n"&gt;pol&lt;/span&gt;
    lcp_writepol -i 0x20000001 -f vl.pol -p &lt;span class="k"&gt;$(&lt;/span&gt;PASSWORD&lt;span class="k"&gt;)&lt;/span&gt;

&lt;span class="nf"&gt;install&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;writelcp&lt;/span&gt;
    cp list.data /boot/list.data
&lt;/pre&gt;&lt;/div&gt;</content><category term="security"></category></entry><entry><title>Hello World</title><link href="https://blog.perfinion.com/2016/08/hello-world/" rel="alternate"></link><published>2016-08-01T22:00:00+08:00</published><updated>2016-08-01T22:00:00+08:00</updated><author><name>Jason Zaman</name></author><id>tag:blog.perfinion.com,2016-08-01:/2016/08/hello-world/</id><summary type="html">Hello World. I've been meaning to start a blog for a while but never got around
to it. Russell Coker posted on the SELinux mailing list yesterday asking about
Planet SELinux so I figured now is as good a time as any for starting one.</summary><content type="html">&lt;p&gt;Hello World. I've been meaning to start a blog for a while but never got around
to it. Russell Coker posted on the SELinux mailing list yesterday asking about
Planet SELinux so I figured now is as good a time as any for starting one.&lt;/p&gt;</content><category term="misc"></category></entry></feed>